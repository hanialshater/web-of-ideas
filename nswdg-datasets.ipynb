{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from annoy import AnnoyIndex\n",
    "import random\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import bisect\n",
    "from scipy.spatial.distance import pdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "filename = './data/glove-25-angular.hdf5'\n",
    "f = h5py.File(filename, 'r')\n",
    "\n",
    "# List all groups\n",
    "# print(\"Keys: %s\" % f.keys())\n",
    "# a_group_key = list(f.keys())[0]\n",
    "\n",
    "# Get the data\n",
    "train_data = list(f['train'])\n",
    "test_data = list(f['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf\n",
    "d = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "G.add_edge(0, 1)\n",
    "G.nodes[0]['val'] = np.random.random(d)\n",
    "G.nodes[1]['val'] = np.random.random(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(a, b):\n",
    "    #return np.linalg.norm(a-b)\n",
    "    return pdist([a, b], \"euclidean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Results:\n",
    "    def __init__(self, max_len=16):\n",
    "        self.data = []\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def insert(self, x):\n",
    "        bisect.insort(self.data, x)\n",
    "        if self.max_len and len(self.data) > self.max_len:\n",
    "            del[self.data[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_search(query, num_restarts=5, max_results=4, max_greedy_steps=10):\n",
    "    candidates = Results(max_len=5)\n",
    "    visited = set([])\n",
    "    results = Results(max_len=None)\n",
    "    \n",
    "    for i in range(num_restarts):\n",
    "        random_entry_point = random.randint(0, len(G.nodes) - 1)\n",
    "        candidates.insert((dist(query, G.nodes[random_entry_point]['val']), random_entry_point))\n",
    "        tempResults = Results(max_len=None)\n",
    "        #TODO: move candidate selection out of the loop to break local minima\n",
    "        for _ in range(max_greedy_steps):\n",
    "            if len(candidates.data) > 0:\n",
    "                best_candidate_val, best_candidate = candidates.data[0]\n",
    "                del candidates.data[0]\n",
    "                if len(tempResults.data) >= max_results and best_candidate_val > tempResults.data[-1][0]:\n",
    "                    break\n",
    "                for n in G.neighbors(best_candidate):\n",
    "                    if n not in visited:\n",
    "                        candidates.insert((dist(G.nodes[n]['val'], query), n))\n",
    "                        tempResults.insert((dist(G.nodes[n]['val'], query), n))\n",
    "                        visited.add(n)\n",
    "        for val, node in tempResults.data:\n",
    "            results.insert((val, node))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert(idx, val):\n",
    "    id = idx\n",
    "    results = knn_search(val, max_greedy_steps=20, max_results=50, num_restarts=50)\n",
    "    for v, n in results.data[:50]:\n",
    "        G.add_edge(id, n)\n",
    "        G.add_edge(n, id)\n",
    "        G.nodes[id]['val'] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune():\n",
    "    for n in G.nodes:\n",
    "        nhbrs = sorted([(dist(G.nodes[n]['val'], G.nodes[nbhr]['val']), nbhr) for nbhr in G.neighbors(n)])\n",
    "        nhbrs = nhbrs[:10] + random.sample(nhbrs[10:], min(40, len(nhbrs[10:])))\n",
    "        nhbrs_ids = [i[1] for i in nhbrs]\n",
    "        for nhbr in list(G.neighbors(n)):\n",
    "            if nhbr not in nhbrs_ids:\n",
    "                G.remove_edge(n, nhbr)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = AnnoyIndex(d, metric=\"euclidean\")  # Length of item vector that will be indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "1h 13min 3s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "for idx, p in enumerate(test_data):\n",
    "    if idx % 500 == 0:\n",
    "        print (idx)\n",
    "    insert(idx, p)\n",
    "    t.add_item(idx, p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune()\n",
    "#t.build(10) # 10 tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 1., 2.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.FloatTensor([1,2,3])\n",
    "t2 = torch.FloatTensor([1,2])\n",
    "torch.cat([t1, t2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Router(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Router, self).__init__()\n",
    "        self.embedding = nn.Embedding(len(G.nodes),8)\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "          torch.nn.Linear(d, 8),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(8, 8),\n",
    "          torch.nn.ReLU()\n",
    "        ).to(device)\n",
    "        self.route_net = torch.nn.Sequential(\n",
    "          torch.nn.Linear(16, 8),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(8, 50),\n",
    "          torch.nn.Softmax()\n",
    "        ).to(device)\n",
    "        \n",
    "    def forward(self, node_id_list, query):\n",
    "        emd = self.embedding(torch.LongTensor(node_id_list))\n",
    "        encoded_query = self.encoder(torch.FloatTensor(query).view(1, -1))\n",
    "        inp = torch.cat((emd.view(-1), encoded_query.view(-1)))\n",
    "        pred_dir = self.route_net(inp)\n",
    "        return pred_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Router()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = list(G.nodes(data=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w_nighbours(node_id, query):\n",
    "    t = torch.FloatTensor([-dist(query, G.nodes[n]['val']) for n in G.neighbors(node_id)])\n",
    "    return torch.softmax(t, 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\torch\\nn\\modules\\container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\torch\\nn\\functional.py:2016: UserWarning: Using a target size (torch.Size([50, 1])) that is different to the input size (torch.Size([1, 50])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09693653136491776\n",
      "0.09824513643980026\n",
      "0.0980229303240776\n",
      "0.09852825105190277\n",
      "0.09840621054172516\n",
      "0.0984981432557106\n",
      "0.09746470302343369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\torch\\nn\\functional.py:2016: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 50])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0976511687040329\n",
      "0.09757306426763535\n",
      "0.09762583673000336\n",
      "0.09790787845849991\n",
      "0.0978493019938469\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(r.parameters(), lr=1e-3)\n",
    "\n",
    "for i in range(1):\n",
    "    random.shuffle(nodes)\n",
    "    r.route_net.requires_grad = True\n",
    "    for idx, random_entry in enumerate(nodes):\n",
    "        if idx > 1000:\n",
    "            r.route_net.requires_grad = False\n",
    "        try:\n",
    "            for j in range(3):\n",
    "                random_point = G.nodes[random.sample(nodes, 1)[0]]['val']\n",
    "                y_pred = r([random_entry], random_point)\n",
    "                loss = loss_fn(y_pred.view(1, -1), get_w_nighbours(random_entry, query=random_point))\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            if idx % 1000 == 0:\n",
    "                print(loss.item())\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_knn(query, num_restarts=5, max_greedy_steps=10):\n",
    "    results = Results(max_len=None)\n",
    "    visited = set([])\n",
    "    for i in range(num_restarts):\n",
    "        current_point = random.randint(0, len(G.nodes) - 1)\n",
    "        for j in range(max_greedy_steps):\n",
    "            pred = r([current_point], query)\n",
    "            nhbrs = list(G.neighbors(current_point))\n",
    "            next_point_idx = [int(k) for k in torch.argsort(pred.view(-1), 0) if nhbrs[int(k)] not in visited]\n",
    "            if not next_point_idx:\n",
    "                break\n",
    "            next_point = nhbrs[next_point_idx[0]]\n",
    "            #this does not work, may be wrong decisions are rectified while proceeding withe algorithm\n",
    "#             if dist(G.nodes[current_point]['val'], query) - dist(G.nodes[next_point]['val'], query) > 0.2:\n",
    "#                 break\n",
    "            current_point = next_point\n",
    "            results.insert((dist(G.nodes[next_point]['val'], query), next_point))\n",
    "            visited.add(next_point)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_knn_(query, num_restarts=5, max_results=4, max_greedy_steps=10):\n",
    "    candidates = Results(max_len=5)\n",
    "    visited = set([])\n",
    "    results = Results(max_len=None)\n",
    "    \n",
    "    for i in range(num_restarts):\n",
    "        random_entry_point = random.randint(0, len(G.nodes) - 1)\n",
    "        candidates.insert((dist(query, G.nodes[random_entry_point]['val']), random_entry_point))\n",
    "        tempResults = Results(max_len=None)\n",
    "        #TODO: move candidate selection out of the loop to break local minima\n",
    "        for _ in range(max_greedy_steps):\n",
    "            if len(candidates.data) > 0:\n",
    "                best_candidate_val, best_candidate = candidates.data[0]\n",
    "                del candidates.data[0]\n",
    "                visited.add(best_candidate)\n",
    "                \n",
    "                if len(tempResults.data) >= max_results and best_candidate_val > tempResults.data[-1][0]:\n",
    "                    break\n",
    "                    \n",
    "                pred = r([best_candidate], query)\n",
    "                nhbrs = list(G.neighbors(best_candidate))\n",
    "                next_point_idx = [int(k) for k in torch.argsort(pred.view(-1), 0) if nhbrs[int(k)] not in visited]\n",
    "                to_add = [nhbrs[n] for n in next_point_idx[:5]]\n",
    "                for n in to_add:\n",
    "                    if n not in visited:\n",
    "                        candidates.insert((dist(G.nodes[n]['val'], query), n))\n",
    "                        tempResults.insert((dist(G.nodes[n]['val'], query), n))\n",
    "                        visited.add(n)\n",
    "        for val, node in tempResults.data:\n",
    "            results.insert((val, node))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_point = random.sample(test_data, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\torch\\nn\\modules\\container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array([4.13469063]), 10746),\n",
       " (array([5.13280338]), 10974),\n",
       " (array([5.33629806]), 10060),\n",
       " (array([5.34439976]), 6552),\n",
       " (array([5.44745123]), 10410),\n",
       " (array([5.45162408]), 11037),\n",
       " (array([5.46896645]), 7545),\n",
       " (array([5.47235525]), 3125),\n",
       " (array([5.48701356]), 2048),\n",
       " (array([5.53063763]), 2166)]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%timeit -n 1 -r 1\n",
    "neural_knn(random_point, max_greedy_steps=10, num_restarts=50).data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\torch\\nn\\modules\\container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array([0.]), 4067),\n",
       " (array([4.13469063]), 10746),\n",
       " (array([4.48703518]), 2335),\n",
       " (array([4.58762304]), 2042),\n",
       " (array([4.68207971]), 10187),\n",
       " (array([4.69303712]), 3855),\n",
       " (array([4.75208318]), 7042),\n",
       " (array([4.83061656]), 8876),\n",
       " (array([4.84047982]), 3435),\n",
       " (array([4.86146194]), 925)]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%timeit -n 1 -r 1\n",
    "neural_knn_(random_point, max_greedy_steps=100, max_results=20, num_restarts=5).data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([0.]), 4067),\n",
       " (array([4.13469063]), 10746),\n",
       " (array([4.48703518]), 2335),\n",
       " (array([4.58762304]), 2042),\n",
       " (array([4.68207971]), 10187),\n",
       " (array([4.68427814]), 2054),\n",
       " (array([4.69303712]), 3855),\n",
       " (array([4.75208318]), 7042),\n",
       " (array([4.79639161]), 2974),\n",
       " (array([4.83061656]), 8876)]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%timeit -n 1 -r 1\n",
    "knn_search(random_point, max_greedy_steps=10, max_results=20, num_restarts=5).data[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([0.]), 4067),\n",
       " (array([4.13469063]), 10746),\n",
       " (array([4.48703518]), 2335),\n",
       " (array([4.58762304]), 2042),\n",
       " (array([4.68207971]), 10187),\n",
       " (array([4.68427814]), 2054),\n",
       " (array([4.69303712]), 3855),\n",
       " (array([4.75208318]), 7042),\n",
       " (array([4.79639161]), 2974),\n",
       " (array([4.83061656]), 8876)]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%timeit -n 1 -r 1\n",
    "sorted([(dist(G.nodes[n]['val'], random_point), n) for n in G.nodes])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2984, 9663, 1252, 9104, 1891, 7202, 1365, 582, 3378, 5467],\n",
       " [0.0,\n",
       "  4.134690761566162,\n",
       "  4.487035274505615,\n",
       "  4.682079315185547,\n",
       "  4.796391487121582,\n",
       "  4.887374401092529,\n",
       "  5.054071426391602,\n",
       "  5.093081951141357,\n",
       "  5.236557960510254,\n",
       "  5.268767356872559])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%timeit -n 1 -r 1\n",
    "t.get_nns_by_vector(random_point,10 , search_k=-1, include_distances=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
